# Gemini API Rate Limiting Configuration
# =====================================

# Basic LLM Configuration
llm.enabled=true
llm.model.type=gemini
llm.gemini.enabled=true
llm.gemini.api.key=YOUR_GEMINI_API_KEY_HERE
llm.gemini.model=gemini-2.0-flash-exp
llm.gemini.api.url=https://generativelanguage.googleapis.com/v1beta/models

# Rate Limiting Configuration
# ===========================

# Enable automatic retry when hitting rate limits (429 errors)
# Set to false to fail immediately on rate limits
llm.rate.limit.retry.enabled=true

# Maximum number of retries for rate limiting
# Each retry waits progressively longer:
# - Retry 1: Wait 60 seconds (1 minute)
# - Retry 2: Wait 90 seconds (1.5 minutes) 
# - Retry 3: Wait 120 seconds (2 minutes)
# 
# Recommended values:
# - 1: Quick fail (total wait: 1 minute)
# - 3: Balanced (total wait: up to 4.5 minutes) - DEFAULT
# - 5: Patient (total wait: up to 10+ minutes)
llm.rate.limit.max.retries=3

# Smart Input Fetching Configuration
# ==================================
smart.input.fetch.enabled=true
smart.input.fetch.percentage=0.9
smart.input.fetch.llm.discovery.enabled=true
smart.input.fetch.max.candidates=5

# Expected Behavior with Rate Limiting:
# =====================================
#
# When Gemini free tier rate limits are hit (429 errors), you'll see:
#
# ‚è≥ [Gemini API] Rate limit hit (429) on attempt 1/3. Waiting 60 seconds before retry...
# ‚è≥ [Gemini API] This is normal for Gemini free tier - we'll automatically retry
# üí§ [Gemini API] Sleeping for 60 seconds to respect rate limits...
# üîÑ [Gemini API] Retrying request (attempt 2/3) after rate limit wait
# ‚úÖ [Gemini API] Request succeeded on attempt 2 after rate limiting
#
# This ensures smart fetch continues working even with API limits!

# Gemini Free Tier Limits (approximate):
# ======================================
# - Requests per minute: ~15 requests
# - Requests per day: ~1,500 requests  
# - Tokens per minute: ~32,000 tokens
#
# Smart fetch typically makes 4-6 LLM calls per parameter:
# - 3-5 calls for endpoint discovery
# - 1 call for value extraction
#
# With 10 parameters = 40-60 LLM calls, which exceeds the per-minute limit.
# The retry mechanism handles this automatically!

# Troubleshooting:
# ===============
#
# If you see many rate limit retries:
# - Consider reducing smart.input.fetch.percentage (e.g., 0.5 for 50%)
# - Increase llm.rate.limit.max.retries for more patience
# - Check your Gemini API quota in Google Cloud Console
#
# If retries are taking too long:
# - Reduce llm.rate.limit.max.retries to 1 or 2
# - Set llm.rate.limit.retry.enabled=false to fail fast
#
# The system will always fall back to reasonable values even if LLM fails!
